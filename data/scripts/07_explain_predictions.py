"""
Generate SHAP explanations for avalanche predictions

SHAP shows which features contribute most to each prediction
Uses TUNED model with optimal threshold
"""

import pandas as pd
import numpy as np
import joblib
import shap
from pathlib import Path
import matplotlib.pyplot as plt
import warnings

warnings.filterwarnings('ignore')

# Paths
DATA_DIR = Path(__file__).parent.parent / 'data'
PROCESSED_DIR = DATA_DIR / 'processed'
MODELS_DIR = DATA_DIR / 'models'
OUTPUTS_DIR = DATA_DIR / 'outputs'
OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)

TRAINING_DATA = PROCESSED_DIR / 'training_data.csv'
TUNED_MODEL = MODELS_DIR / 'avalanche_classifier_tuned.pkl'


def load_model_and_data():
    """Load tuned model and test data"""
    
    print("Loading tuned model and data...")
    
    # Load tuned model package (includes optimal threshold!)
    model_package = joblib.load(TUNED_MODEL)
    
    model = model_package['model']
    optimal_threshold = model_package['optimal_threshold']
    feature_cols = model_package['feature_cols']
    
    print(f"âœ“ Loaded tuned model")
    print(f"  Optimal threshold: {optimal_threshold:.2f}")
    print(f"  Features: {', '.join(feature_cols)}")
    
    # Load data
    df = pd.read_csv(TRAINING_DATA)
    
    # Get clean data
    X = df[feature_cols].dropna()
    y = df.loc[X.index, 'avalanche_occurred']
    
    # Get a sample for SHAP (100 examples for speed)
    sample_indices = np.random.choice(len(X), size=min(100, len(X)), replace=False)
    X_sample = X.iloc[sample_indices]
    
    return model, optimal_threshold, X, X_sample, feature_cols


def explain_single_prediction(model, optimal_threshold, X, feature_cols, index=0):
    """
    Explain a single prediction with SHAP
    
    Shows which features pushed the prediction toward high/low risk
    """
    
    print("\n" + "="*60)
    print("SINGLE PREDICTION EXPLANATION")
    print("="*60)
    
    # Get one example
    x = X.iloc[index:index+1]
    
    print("\nInput features:")
    for feature, value in zip(feature_cols, x.values[0]):
        print(f"  {feature:15s}: {value:.2f}")
    
    # Predict
    prediction = model.predict_proba(x)[0, 1]
    
    # Use TUNED threshold for risk level
    if prediction >= optimal_threshold:
        risk_level = "HIGH DANGER"
        risk_color = "ðŸ”´"
    else:
        risk_level = "LOW/SAFE"
        risk_color = "ðŸŸ¢"
    
    print(f"\n{risk_color} Prediction: {prediction*100:.1f}% avalanche probability")
    print(f"Risk Level: {risk_level} (threshold: {optimal_threshold:.2f})")
    
    # Create SHAP explainer
    print("\nCalculating SHAP values...")
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(x)
    
    # Handle different SHAP return formats
    if isinstance(shap_values, list):
        # Binary classification returns [class_0_shap, class_1_shap]
        shap_vals = shap_values[1][0]  # Get avalanche class, first sample
    else:
        # Single array
        shap_vals = shap_values[0]
    
    # Ensure it's a 1D array
    if len(shap_vals.shape) > 1:
        shap_vals = shap_vals.flatten()
    
    # FIX: Take only the first N values matching number of features
    n_features = len(feature_cols)
    shap_vals = shap_vals[:n_features]
    
    print(f"Features: {n_features}, SHAP values: {len(shap_vals)}")  # Debug
    
    # Show feature contributions
    print("\n" + "="*60)
    print("FEATURE CONTRIBUTIONS")
    print("="*60)
    
    contributions = pd.DataFrame({
        'feature': feature_cols,
        'value': x.values[0],
        'shap_value': shap_vals,
        'impact': ['â†‘ INCREASES RISK' if s > 0 else 'â†“ DECREASES RISK' for s in shap_vals]
    })
    
    contributions['abs_shap'] = contributions['shap_value'].abs()
    contributions = contributions.sort_values('abs_shap', ascending=False)
    
    print("\nTop factors (sorted by importance):")
    for _, row in contributions.iterrows():
        impact_symbol = "ðŸ”º" if row['shap_value'] > 0 else "ðŸ”»"
        print(f"\n{impact_symbol} {row['feature'].upper()}: {row['value']:.1f}")
        print(f"  Impact: {row['shap_value']:+.3f} {row['impact']}")
    
    return contributions, prediction


def explain_dataset(model, X_sample, feature_cols):
    """
    Global feature importance across entire dataset
    
    Shows which features are most important overall
    """
    
    print("\n" + "="*60)
    print("GLOBAL FEATURE IMPORTANCE (SHAP)")
    print("="*60)
    
    print(f"\nCalculating SHAP values for {len(X_sample)} samples...")
    
    # Create explainer
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X_sample)
    
    # For binary classification
    if isinstance(shap_values, list):
        shap_values = shap_values[1]  # Avalanche class
    
    # FIX: Handle 3D shape (samples, features, classes)
    print(f"SHAP values shape: {shap_values.shape}")
    
    if len(shap_values.shape) == 3:
        # Shape is (samples, features, classes) - take class 1 (avalanche)
        print("Detected 3D shape, selecting avalanche class (index 1)")
        shap_values = shap_values[:, :, 1]  # Now (samples, features)
    
    # If still wrong shape, slice to correct number of features
    n_features = len(feature_cols)
    if shap_values.shape[1] != n_features:
        print(f"Fixing shape mismatch: {shap_values.shape[1]} -> {n_features}")
        shap_values = shap_values[:, :n_features]
    
    print(f"Final SHAP shape: {shap_values.shape}")
    
    # Calculate mean absolute SHAP values
    mean_shap = np.abs(shap_values).mean(axis=0)
    
    # Verify dimensions match
    print(f"Features: {len(feature_cols)}, Mean SHAP: {len(mean_shap)}")
    
    importance_df = pd.DataFrame({
        'feature': feature_cols,
        'mean_shap': mean_shap
    }).sort_values('mean_shap', ascending=False)
    
    print("\nGlobal feature importance:")
    print(importance_df.to_string(index=False))
    
    # Create summary plot
    print("\nGenerating SHAP summary plot...")
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values, X_sample, feature_names=feature_cols, show=False)
    plt.tight_layout()
    plt.savefig(OUTPUTS_DIR / 'shap_summary.png', dpi=300, bbox_inches='tight')
    print(f"âœ“ Saved to: {OUTPUTS_DIR / 'shap_summary.png'}")
    plt.close()
    
    return importance_df


def create_waterfall_explanation(model, X, feature_cols, index=0):
    """
    Create waterfall plot showing how features add up to final prediction
    
    Starts from base rate and shows each feature's contribution
    """
    
    print("\n" + "="*60)
    print("WATERFALL EXPLANATION")
    print("="*60)
    
    # Get example
    x = X.iloc[index:index+1]
    
    # Calculate SHAP (use shap_values() for consistent binary-class handling)
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(x)
    
    # Binary classification: get single explanation for avalanche (positive) class
    if isinstance(shap_values, list):
        # [class_0, class_1] -> use class_1 for first sample
        sv = shap_values[1][0]  # (n_features,)
    else:
        sv = shap_values[0]
        if sv.ndim == 2 and sv.shape[1] == 2:
            sv = sv[:, 1]  # (n_features, 2) -> take avalanche class
        elif sv.ndim > 1:
            sv = sv.flatten()[:len(feature_cols)]
    single_explanation = np.asarray(sv).flatten()[:len(feature_cols)]
    
    # Base value for positive class (for waterfall start)
    base_value = explainer.expected_value
    if isinstance(base_value, np.ndarray):
        base_value = base_value[1]
    
    # Build Explanation so waterfall has feature names and data
    explanation = shap.Explanation(
        values=single_explanation,
        base_values=base_value,
        data=x.values[0],
        feature_names=feature_cols,
    )
    
    # Create waterfall plot
    print("\nGenerating waterfall plot...")
    plt.figure(figsize=(10, 6))
    shap.plots.waterfall(explanation, max_display=10, show=False)
    plt.tight_layout()
    plt.savefig(OUTPUTS_DIR / 'shap_waterfall.png', dpi=300, bbox_inches='tight')
    print(f"âœ“ Saved to: {OUTPUTS_DIR / 'shap_waterfall.png'}")
    plt.close()


def generate_human_readable_explanation(contributions, prediction, optimal_threshold):
    """
    Convert SHAP values into plain English explanation
    Uses TUNED threshold for risk assessment
    """
    
    print("\n" + "="*60)
    print("HUMAN-READABLE EXPLANATION")
    print("="*60)
    
    # Use tuned threshold
    if prediction >= optimal_threshold:
        risk_level = "HIGH DANGER"
        risk_icon = "ðŸ”´"
    elif prediction >= (optimal_threshold - 0.1):
        risk_level = "MODERATE"
        risk_icon = "ðŸŸ¡"
    else:
        risk_level = "LOW/SAFE"
        risk_icon = "ðŸŸ¢"
    
    explanation = f"\n{risk_icon} **AVALANCHE RISK: {risk_level} ({prediction*100:.0f}%)**\n"
    explanation += f"(Decision threshold: {optimal_threshold:.2f})\n"
    
    # Get top 3 positive contributors
    positive = contributions[contributions['shap_value'] > 0].head(3)
    
    if len(positive) > 0:
        explanation += "\n**Factors INCREASING risk:**\n"
        for _, row in positive.iterrows():
            explanation += f"  ðŸ”º {row['feature'].replace('_', ' ').title()}: {row['value']:.1f}"
            
            # Add context
            if row['feature'] == 'new_snow_24h' and row['value'] > 20:
                explanation += " (heavy recent snowfall - CRITICAL)"
            elif row['feature'] == 'slope' and row['value'] > 35:
                explanation += " (steep slope - HIGH IMPACT)"
            elif row['feature'] == 'temp' and row['value'] > 0:
                explanation += " (warming temps - unstable snow)"
            elif row['feature'] == 'snow_depth' and row['value'] > 150:
                explanation += " (very deep snowpack)"
            
            explanation += f" [+{row['shap_value']:.2f}]"
            explanation += "\n"
    
    # Get top 3 negative contributors
    negative = contributions[contributions['shap_value'] < 0].head(3)
    
    if len(negative) > 0:
        explanation += "\n**Factors DECREASING risk:**\n"
        for _, row in negative.iterrows():
            explanation += f"  ðŸ”» {row['feature'].replace('_', ' ').title()}: {row['value']:.1f}"
            
            # Add context
            if row['feature'] == 'new_snow_24h' and row['value'] < 5:
                explanation += " (minimal new snow)"
            elif row['feature'] == 'temp' and row['value'] < -10:
                explanation += " (cold temps - stable snow)"
            elif row['feature'] == 'slope' and row['value'] < 30:
                explanation += " (gentler slope)"
            
            explanation += f" [{row['shap_value']:.2f}]"
            explanation += "\n"
    
    # Recommendation based on TUNED threshold
    explanation += "\n**Recommendation:**\n"
    if prediction >= optimal_threshold:
        explanation += "  âš ï¸ DANGEROUS CONDITIONS. Avoid all avalanche terrain.\n"
        explanation += f"  Model is {(prediction/optimal_threshold - 1)*100:.0f}% above safety threshold."
    elif prediction >= (optimal_threshold - 0.1):
        explanation += "  âš ï¸ CONSIDERABLE DANGER. Careful snowpack evaluation required.\n"
        explanation += "  Conditions approaching unsafe levels."
    else:
        explanation += "  âœ“ LOW DANGER. Normal caution advised.\n"
        explanation += f"  {((optimal_threshold - prediction)/optimal_threshold)*100:.0f}% below danger threshold."
    
    print(explanation)
    
    # Save to file
    with open(OUTPUTS_DIR / 'explanation.txt', 'w') as f:
        f.write(explanation)
    print(f"\nâœ“ Saved to: {OUTPUTS_DIR / 'explanation.txt'}")
    
    return explanation


def test_multiple_scenarios(model, optimal_threshold, feature_cols):
    """
    Test model on different scenarios to show how it behaves
    """
    
    print("\n" + "="*60)
    print("TESTING DIFFERENT SCENARIOS")
    print("="*60)
    
    scenarios = [
        {
            'name': 'Heavy new snow on steep slope',
            'elevation': 3400,
            'slope': 38,
            'aspect_degrees': 315,
            'snow_depth': 125,
            'new_snow_24h': 35,  # Heavy!
            'swe': 32,
            'temp': -5
        },
        {
            'name': 'Deep snowpack but no new snow',
            'elevation': 3400,
            'slope': 38,
            'aspect_degrees': 315,
            'snow_depth': 200,
            'new_snow_24h': 0,  # Stable
            'swe': 60,
            'temp': -12
        },
        {
            'name': 'Warming temps on loaded slope',
            'elevation': 3200,
            'slope': 40,
            'aspect_degrees': 180,
            'snow_depth': 130,
            'new_snow_24h': 15,
            'swe': 35,
            'temp': 2  # Above freezing!
        },
        {
            'name': 'Low angle, minimal snow',
            'elevation': 2800,
            'slope': 25,
            'aspect_degrees': 90,
            'snow_depth': 50,
            'new_snow_24h': 2,
            'swe': 12,
            'temp': -8
        }
    ]
    
    for scenario in scenarios:
        name = scenario.pop('name')
        X_test = pd.DataFrame([scenario])
        
        prob = model.predict_proba(X_test)[0, 1]
        prediction = "DANGER" if prob >= optimal_threshold else "SAFE"
        
        print(f"\n{name}:")
        print(f"  Probability: {prob:.1%}")
        print(f"  Prediction: {prediction}")


def main():
    """Run all explanations with tuned model"""
    
    # Load tuned model and data
    model, optimal_threshold, X_full, X_sample, feature_cols = load_model_and_data()
    
    # 1. Explain single prediction
    contributions, prediction = explain_single_prediction(
        model, optimal_threshold, X_full, feature_cols, index=0
    )
    
    # 2. Global importance
    importance_df = explain_dataset(model, X_sample, feature_cols)
    
    # 3. Waterfall plot
    create_waterfall_explanation(model, X_full, feature_cols, index=0)
    
    # 4. Human-readable explanation
    explanation = generate_human_readable_explanation(
        contributions, prediction, optimal_threshold
    )
    
    # 5. Test different scenarios
    test_multiple_scenarios(model, optimal_threshold, feature_cols)
    
    print("\n" + "="*60)
    print("EXPLANATIONS COMPLETE")
    print("="*60)
    print(f"\nOutputs saved in: {OUTPUTS_DIR}")
    print(f"\nUsing tuned model with threshold: {optimal_threshold:.2f}")
    print("This threshold catches 87.8% of avalanches (missing only 12.2%)")
    
    return contributions, importance_df


if __name__ == "__main__":
    contributions, importance = main()